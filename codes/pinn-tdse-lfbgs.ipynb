{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798f7f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# use float64 for higher precision in PDEs\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "DTYPE = tf.float64\n",
    "\n",
    "# declare inputs entire domain\n",
    "w_min, w_max = tf.constant(0.75, dtype=DTYPE), tf.constant(2.0, dtype=DTYPE)\n",
    "pi = tf.constant(np.pi, dtype=DTYPE)\n",
    "x_min, x_max = -pi, pi\n",
    "t_min, t_max = tf.constant(0.0, dtype=DTYPE), 2.0*pi\n",
    "\n",
    "# generate grid points\n",
    "def generate_grid_samples(x_min, x_max, t_min, t_max, N_x, N_t):\n",
    "    x = tf.linspace(x_min, x_max, N_x)\n",
    "    t = tf.linspace(t_min, t_max, N_t)\n",
    "    X, T = tf.meshgrid(x, t)\n",
    "    x_flat = tf.reshape(X, [-1, 1])\n",
    "    t_flat = tf.reshape(T, [-1, 1])\n",
    "    return x_flat, t_flat\n",
    "\n",
    "# generate batch parameters\n",
    "def generate_batch_params(w_cmin, w_cmax, N, w_fix):\n",
    "    w_var = tf.random.uniform((int(N*0.8), 1), w_cmin, w_cmax, dtype=DTYPE)\n",
    "    w_fixed = tf.ones((int(N*0.2), 1), dtype=DTYPE) * w_fix\n",
    "    return tf.concat([w_var, w_fixed], axis=0)\n",
    "\n",
    "# scale inputs\n",
    "def scale_inputs(input, input_min, input_max):\n",
    "    return 2.0 * (input - input_min) / (input_max - input_min) - 1.0\n",
    "\n",
    "# initial condition\n",
    "def psi_init(x, w, pi):\n",
    "    u_0 = (w/pi)**0.25 * tf.math.exp(-0.5*w*x**2)\n",
    "    u_1 = (w/pi)**0.25 * tf.math.exp(-0.5*w*x**2) * x * tf.math.sqrt(2.0*w)\n",
    "    return (1.0/np.sqrt(2.0)) * (u_0 + u_1)\n",
    "\n",
    "# data generation\n",
    "N_xt, N_b, N_i, N_grid = 70, 700, 900, 200\n",
    "\n",
    "# curriculum training\n",
    "w_choice = tf.constant(1.0, dtype=DTYPE)\n",
    "# w_cmin, w_cmax = tf.constant(0.95, dtype=DTYPE), tf.constant(1.05, dtype=DTYPE)\n",
    "t_cmin, t_cmax = tf.constant(0.0, dtype=DTYPE), 2.0*pi\n",
    "\n",
    "# interior points\n",
    "x_f, t_f = generate_grid_samples(x_min, x_max, t_cmin, t_cmax, N_xt, N_xt)\n",
    "# w_f = generate_batch_params(w_cmin, w_cmax, N_xt*N_xt, w_choice)\n",
    "w_f = tf.ones_like(x_f) * w_choice\n",
    "x_fs = scale_inputs(x_f, x_min, x_max)  # scaled\n",
    "t_fs = scale_inputs(t_f, t_min, t_max)  # scaled\n",
    "w_fs = scale_inputs(w_f, w_min, w_max)  # scaled\n",
    "\n",
    "# boundary points\n",
    "x_b = tf.concat([tf.ones((N_b//2, 1), dtype=DTYPE) * x_min,\n",
    "                 tf.ones((N_b//2, 1), dtype=DTYPE) * x_max], axis=0)\n",
    "t_b = tf.linspace(t_cmin, t_cmax, N_b//2)[:, None]\n",
    "t_b = tf.tile(t_b, [2, 1])\n",
    "# w_b = generate_batch_params(w_cmin, w_cmax, N_b, w_choice)\n",
    "w_b = tf.ones_like(t_b) * w_choice\n",
    "x_bs = scale_inputs(x_b, x_min, x_max)  # scaled\n",
    "t_bs = scale_inputs(t_b, t_min, t_max)  # scaled\n",
    "w_bs = scale_inputs(w_b, w_min, w_max)  # scaled\n",
    "\n",
    "# initial points\n",
    "x_i = tf.linspace(x_min, x_max, N_i)[:, None]\n",
    "t_i = tf.zeros_like(x_i, dtype=DTYPE)\n",
    "# w_i = generate_batch_params(w_cmin, w_cmax, N_i, w_choice)\n",
    "w_i = tf.ones_like(x_i) * w_choice\n",
    "x_is = scale_inputs(x_i, x_min, x_max)  # scaled\n",
    "t_is = scale_inputs(t_i, t_min, t_max)  # scaled\n",
    "w_is = scale_inputs(w_i, w_min, w_max)  # scaled\n",
    "\n",
    "psi_i = tf.cast(psi_init(x_i, w_i, pi), tf.complex128)\n",
    "\n",
    "# grid for normalization penalty\n",
    "x_n = tf.linspace(x_min, x_max, N_grid)[:, None]\n",
    "x_ns = scale_inputs(x_n, x_min, x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ba899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shapes and data types\n",
    "print('x_i')\n",
    "print(tf.shape(x_is))\n",
    "print(x_is.dtype)\n",
    "print(tf.shape(t_is))\n",
    "print(t_is.dtype, '\\n')\n",
    "\n",
    "print('x_b')\n",
    "print(tf.shape(x_bs))\n",
    "print(x_bs.dtype)\n",
    "print(tf.shape(t_bs))\n",
    "print(t_bs.dtype, '\\n')\n",
    "\n",
    "print('x_f')\n",
    "print(tf.shape(x_fs))\n",
    "print(x_fs.dtype)\n",
    "print(tf.shape(t_fs))\n",
    "print(t_fs.dtype, '\\n')\n",
    "\n",
    "print('x_n')\n",
    "print(tf.shape(x_ns))\n",
    "print(x_ns.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data points\n",
    "\n",
    "# plotting collocation, boundary, and initial points\n",
    "plt.scatter(x_f, t_f, alpha=0.5, linewidths=1e-6, label=f'{N_xt*N_xt} collocation points')\n",
    "plt.scatter(x_b, t_b, alpha=0.5, linewidths=1e-6, label=f'{N_b} boundary points')\n",
    "plt.scatter(x_i, t_i, alpha=0.5, linewidths=1e-6, label=f'{N_i} initial points')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('Unscaled Inputs')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x_fs, t_fs, alpha=0.5, linewidths=1e-6, label=f'{N_xt*N_xt} collocation points')\n",
    "plt.scatter(x_bs, t_bs, alpha=0.5, linewidths=1e-6, label=f'{N_b} boundary points')\n",
    "plt.scatter(x_is, t_is, alpha=0.5, linewidths=1e-6, label=f'{N_i} initial points')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('Scaled Inputs')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd679d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier feature layer\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class FourierFeatureLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, mapping_size=512, scale=10.0, **kwargs):\n",
    "        super(FourierFeatureLayer, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.mapping_size = mapping_size\n",
    "        self.scale = scale\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.B = self.add_weight(name=\"B\",\n",
    "                                 shape=[self.input_dim, self.mapping_size],\n",
    "                                 initializer=tf.random_normal_initializer(stddev=self.scale),\n",
    "                                 trainable=False)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x_proj = tf.matmul(x, self.B)\n",
    "        return tf.concat([tf.math.sin(x_proj), tf.math.cos(x_proj)], axis=-1)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"mapping_size\": self.mapping_size,\n",
    "            \"scale\": self.scale\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "# Define the Neural Network\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class PINN(tf.keras.Model):\n",
    "    def __init__(self, input_dim=3, mapping_size=512, scale=10.0, **kwargs):\n",
    "        super(PINN, self).__init__(**kwargs)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.mapping_size = mapping_size\n",
    "        self.scale = scale\n",
    "\n",
    "        self.fourier = FourierFeatureLayer(input_dim=input_dim, mapping_size=mapping_size, scale=scale)\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.dense3 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.dense4 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.dense5 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.dense6 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.out = tf.keras.layers.Dense(2, activation='linear', kernel_initializer=initializer) # u_Re, u_Im\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.fourier(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.dense6(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"mapping_size\": self.mapping_size,\n",
    "            \"scale\": self.scale\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "    \n",
    "# We use Hartree atomic units \\hbar = m = 1\n",
    "# Define the Physics Loss\n",
    "@tf.function\n",
    "def pde_residual(model, x, t, w):\n",
    "    with tf.GradientTape(persistent=True) as tape2:\n",
    "        tape2.watch([x, t])\n",
    "        with tf.GradientTape(persistent=True) as tape1:\n",
    "            tape1.watch([x, t])\n",
    "            xs = scale_inputs(x, x_min, x_max)\n",
    "            ts = scale_inputs(t, t_min, t_max)\n",
    "            ws = scale_inputs(w, w_min, w_max)\n",
    "            X = tf.concat([xs, ts, ws], axis=1)\n",
    "            # uv = tf.clip_by_value(model(X), -1e2, 1e2) # prevent extreme values\n",
    "            uv = model(X)\n",
    "            u, v = uv[:, 0:1], uv[:, 1:2]\n",
    "        u_x = tape1.gradient(u, x) #, unconnected_gradients='zero')\n",
    "        v_x = tape1.gradient(v, x) #, unconnected_gradients='zero')\n",
    "        u_t = tape1.gradient(u, t) #, unconnected_gradients='zero')\n",
    "        v_t = tape1.gradient(v, t) #, unconnected_gradients='zero')\n",
    "    u_xx = tape2.gradient(u_x, x) #, unconnected_gradients='zero')\n",
    "    v_xx = tape2.gradient(v_x, x) #, unconnected_gradients='zero')\n",
    "    del tape1, tape2\n",
    "\n",
    "    potential = 0.5 * w**2 * x**2\n",
    "\n",
    "    f_u = -v_t + 0.5*u_xx - potential*u\n",
    "    f_v = u_t + 0.5*v_xx - potential*v\n",
    "\n",
    "    return f_u, f_v\n",
    "\n",
    "@tf.function\n",
    "def norm_loss(model, x_ns, N_t):\n",
    "    t_n = tf.random.uniform((N_t, 1), t_cmin, t_cmax, dtype=DTYPE)\n",
    "    t_ns = scale_inputs(t_n, t_min, t_max)\n",
    "    # w_rand = tf.random.uniform((), w_cmin, w_cmax, dtype=DTYPE)\n",
    "    w_n = tf.ones_like(x_ns) * w_choice\n",
    "    w_ns = scale_inputs(w_n, w_min, w_max)\n",
    "    norm_penalty_total = 0.0\n",
    "    for t_val in tf.unstack(t_ns, axis=0):\n",
    "        t_in = tf.ones_like(x_ns) * t_val\n",
    "        X = tf.concat([x_ns, t_in, w_ns], axis=1)\n",
    "        uv = model(X)\n",
    "        dx = (x_max - x_min) / tf.cast(tf.shape(x_ns)[0], dtype=DTYPE)\n",
    "        norm = tf.reduce_sum(tf.math.abs(uv)**2) * dx\n",
    "        norm_penalty_total += tf.square(norm - 1.0)\n",
    "    norm_penalty = norm_penalty_total / tf.cast(N_t, dtype=DTYPE)\n",
    "\n",
    "    return norm_penalty\n",
    "\n",
    "@tf.function\n",
    "def loss_fn(model, interior, boundary, initial, norm_grid, omega):\n",
    "    x_f, t_f = interior\n",
    "    x_b, t_b = boundary\n",
    "    x_i, t_i, psi_i = initial\n",
    "    x_grid, N_t = norm_grid\n",
    "    w_f, w_b, w_i = omega\n",
    "\n",
    "    f_u, f_v = pde_residual(model, x_f, t_f, w_f)\n",
    "    loss_f = tf.reduce_mean(tf.square(f_u) + tf.square(f_v)) # / tf.cast(tf.shape(x_f)[0], dtype=DTYPE)\n",
    "\n",
    "    uv_b = model(tf.concat([x_b, t_b, w_b], axis=1))\n",
    "    loss_b = tf.reduce_mean(tf.square(uv_b[:, 0:1]) + tf.square(uv_b[:, 1:2])) # / tf.cast(tf.shape(x_b)[0], dtype=DTYPE)\n",
    "\n",
    "    uv_i = model(tf.concat([x_i, t_i, w_i], axis=1))\n",
    "    loss_i = tf.reduce_mean(tf.square(uv_i[:, 0:1] - tf.math.real(psi_i)) +\n",
    "                            tf.square(uv_i[:, 1:2] - tf.math.imag(psi_i))) # / tf.cast(tf.shape(x_i)[0], dtype=DTYPE)\n",
    "    \n",
    "    norm_penalty = norm_loss(model, x_grid, N_t)\n",
    "    \n",
    "    return loss_f + loss_b + loss_i + norm_penalty, (loss_f, loss_b, loss_i, norm_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121ecc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded for L-BFGS fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Reload the best model before L-BFGS (optional but safe)\n",
    "pinn = tf.keras.models.load_model('best_model_lbf.keras', custom_objects={'PINN': PINN})\n",
    "print(\"Best model loaded for L-BFGS fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287e67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data as global/static references\n",
    "interior_data = (x_f, t_f)\n",
    "boundary_data = (x_bs, t_bs)\n",
    "initial_data = (x_is, t_is, psi_i)\n",
    "norm_grid_data = (x_ns, 20)\n",
    "omega_data = (w_f, w_bs, w_is)\n",
    "\n",
    "# Utility functions for L-BFGS\n",
    "def get_flat_weights(model):\n",
    "    return tf.concat([tf.reshape(w, [-1]) for w in model.trainable_variables], axis=0)\n",
    "\n",
    "def set_flat_weights(model, flat_weights):\n",
    "    idx = 0\n",
    "    for w in model.trainable_variables:\n",
    "        shape = tf.shape(w)\n",
    "        size = tf.reduce_prod(shape)\n",
    "        new_val = tf.reshape(flat_weights[idx:idx+size], shape)\n",
    "        w.assign(new_val)\n",
    "        idx += size\n",
    "\n",
    "def make_loss_fn(model):\n",
    "    def loss_fn_wrapped():\n",
    "        loss, _ = loss_fn(model, (x_f, t_f), (x_bs, t_bs), (x_is, t_is, psi_i), (x_ns, 20), (w_f, w_bs, w_is))\n",
    "        return loss\n",
    "    return loss_fn_wrapped\n",
    "\n",
    "def wrap_loss_and_grads(model, loss_fn_wrapped):\n",
    "    def loss_and_grads(flat_weights):\n",
    "        set_flat_weights(model, flat_weights)\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss_fn_wrapped()\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        flat_grads = tf.concat([tf.reshape(g, [-1]) for g in grads], axis=0)\n",
    "        return loss_value, flat_grads\n",
    "    return loss_and_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca4ce5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting L-BFGS optimization...\n",
      "L-BFGS optimization finished.\n",
      "Final Loss = 3.383238e-05 : (PDE=3.058e-05, BC=1.959e-06, IC=1.229e-06, NORM=6.398e-08)\n",
      "Model saved after L-BFGS optimization.\n"
     ]
    }
   ],
   "source": [
    "# Apply L-BFGS\n",
    "\n",
    "flat_init = get_flat_weights(pinn)\n",
    "wrapped_loss = make_loss_fn(pinn)\n",
    "loss_grad_fn = wrap_loss_and_grads(pinn, wrapped_loss)\n",
    "\n",
    "print(\"Starting L-BFGS optimization...\")\n",
    "results = tfp.optimizer.lbfgs_minimize(\n",
    "    value_and_gradients_function=loss_grad_fn,\n",
    "    initial_position=flat_init,\n",
    "    max_iterations=50000,\n",
    "    tolerance=1e-9\n",
    ")\n",
    "set_flat_weights(pinn, results.position)\n",
    "print(\"L-BFGS optimization finished.\")\n",
    "\n",
    "# Final loss breakdown\n",
    "final_loss, (lf, lb, li, ln) = loss_fn(pinn, (x_f, t_f), (x_bs, t_bs), (x_is, t_is, psi_i), (x_ns, 10), (w_f, w_bs, w_is))\n",
    "print(f\"Final Loss = {final_loss.numpy():.6e} : (PDE={lf.numpy():.3e}, BC={lb.numpy():.3e}, IC={li.numpy():.3e}, NORM={ln.numpy():.3e})\")\n",
    "\n",
    "pinn.save(\"best_model_lbf.keras\")\n",
    "print(\"Model saved after L-BFGS optimization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# use float64 for higher precision in PDEs\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "DTYPE = tf.float64\n",
    "\n",
    "# declare inputs\n",
    "# w_min, w_max = tf.constant(0.75, dtype=DTYPE), tf.constant(2.0, dtype=DTYPE)\n",
    "w_choice = tf.constant(1.0, dtype=DTYPE)\n",
    "pi = tf.constant(np.pi, dtype=DTYPE)\n",
    "x_min, x_max = -pi, pi\n",
    "t_min, t_max = tf.constant(0.0, dtype=DTYPE), 2.0*pi\n",
    "\n",
    "# scale inputs\n",
    "@tf.function\n",
    "def scale_inputs(input, input_min, input_max):\n",
    "    return 2.0 * (input - input_min) / (input_max - input_min) - 1.0\n",
    "\n",
    "# # renormalization\n",
    "# @tf.function\n",
    "# def normalization(input_min, input_max, N, psi_Re, psi_Im):\n",
    "#     dx = (input_max - input_min) / tf.cast(N, dtype=DTYPE)\n",
    "#     norm = tf.math.sqrt(tf.reduce_sum(psi_Re**2 + psi_Im**2) * dx)\n",
    "#     return (psi_Re/norm), (psi_Im/norm)\n",
    "\n",
    "# initial condition\n",
    "@tf.function\n",
    "def psi_init(x, w, pi):\n",
    "    u_0 = (w/pi)**0.25 * tf.math.exp(-0.5*w*x**2)\n",
    "    u_1 = (w/pi)**0.25 * tf.math.exp(-0.5*w*x**2) * x * tf.math.sqrt(2.0*w)\n",
    "    return (1.0/np.sqrt(2.0)) * (u_0 + u_1)\n",
    "\n",
    "# data generation\n",
    "N_f, N_b, N_i, N_grid = 5000, 1000, 1000, 200\n",
    "\n",
    "# interior points\n",
    "x_f = tf.random.uniform((N_f, 1), x_min, x_max, dtype=DTYPE)\n",
    "t_f = tf.random.uniform((N_f, 1), t_min, t_max, dtype=DTYPE)\n",
    "x_fs = scale_inputs(x_f, x_min, x_max)  # scaled\n",
    "t_fs = scale_inputs(t_f, t_min, t_max)  # scaled\n",
    "\n",
    "# boundary points\n",
    "x_b = tf.concat([tf.ones((N_b//2, 1), dtype=DTYPE) * x_min,\n",
    "                 tf.ones((N_b//2, 1), dtype=DTYPE) * x_max], axis=0)\n",
    "t_b = tf.random.uniform((N_b, 1), t_min, t_max, dtype=DTYPE)\n",
    "x_bs = scale_inputs(x_b, x_min, x_max)  # scaled\n",
    "t_bs = scale_inputs(t_b, t_min, t_max)  # scaled\n",
    "\n",
    "# initial points\n",
    "x_i = tf.random.uniform((N_i, 1), x_min, x_max, dtype=DTYPE)\n",
    "t_i = tf.zeros_like(x_i, dtype=DTYPE)\n",
    "x_is = scale_inputs(x_i, x_min, x_max)  # scaled\n",
    "t_is = scale_inputs(t_i, t_min, t_max)  # scaled\n",
    "\n",
    "psi_i = tf.cast(psi_init(x_i, w_choice, pi), tf.complex128)\n",
    "\n",
    "# grid for normalization penalty\n",
    "x_n = tf.linspace(x_min, x_max, N_grid)[:, None]\n",
    "x_ns = scale_inputs(x_n, x_min, x_max)\n",
    "\n",
    "# verify normalization\n",
    "dx_i = (x_max - x_min) / N_i\n",
    "norm_check = tf.reduce_sum(tf.math.abs(psi_i)**2) * dx_i\n",
    "print(f'Normalization check for the initial condition: $|\\Psi(x,0)|**2={norm_check}$')\n",
    "\n",
    "# Fourier feature layer\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class FourierFeatureLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, mapping_size=512, scale=10.0, **kwargs):\n",
    "        super(FourierFeatureLayer, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.mapping_size = mapping_size\n",
    "        self.scale = scale\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.B = self.add_weight(name=\"B\",\n",
    "                                 shape=[self.input_dim, self.mapping_size],\n",
    "                                 initializer=tf.random_normal_initializer(stddev=self.scale),\n",
    "                                 trainable=False)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x_proj = tf.matmul(x, self.B)\n",
    "        return tf.concat([tf.math.sin(x_proj), tf.math.cos(x_proj)], axis=-1)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"mapping_size\": self.mapping_size,\n",
    "            \"scale\": self.scale\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "# Define the Neural Network\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class PINN(tf.keras.Model):\n",
    "    def __init__(self, input_dim=2, mapping_size=512, scale=10.0, **kwargs):\n",
    "        super(PINN, self).__init__(**kwargs)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.mapping_size = mapping_size\n",
    "        self.scale = scale\n",
    "\n",
    "        self.fourier = FourierFeatureLayer(input_dim=input_dim, mapping_size=mapping_size, scale=scale)\n",
    "        initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.dense3 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.dense4 = tf.keras.layers.Dense(512, activation='tanh', kernel_initializer=initializer)\n",
    "        self.out = tf.keras.layers.Dense(2, activation='linear', kernel_initializer=initializer) # u_Re, u_Im\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.fourier(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"mapping_size\": self.mapping_size,\n",
    "            \"scale\": self.scale\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "    \n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('best_model_w1_lbf_2.keras', custom_objects={'PINN': PINN})\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "loaded_model.summary()\n",
    "\n",
    "################## Plot: Contour Plot ###############################\n",
    "\n",
    "# Contour Plot\n",
    "N = 100\n",
    "x_plot = np.linspace(x_min, x_max, N)[:,None]\n",
    "t_plot = np.linspace(t_min, t_max, N)[:,None]\n",
    "x_plot_scaled = scale_inputs(x_plot, x_min, x_max)\n",
    "t_plot_scaled = scale_inputs(t_plot, t_min, t_max)\n",
    "X_grid, T_grid = np.meshgrid(x_plot, t_plot)  # t and x grid\n",
    "\n",
    "x_plot_in = tf.convert_to_tensor(x_plot_scaled, dtype=DTYPE)\n",
    "t_plot_in = tf.convert_to_tensor(t_plot_scaled, dtype=DTYPE)\n",
    "\n",
    "density_interior = []\n",
    "\n",
    "count = 0\n",
    "for t_val in tf.unstack(t_plot_in, axis=0):\n",
    "    t_in = tf.ones_like(x_plot_in) * t_val\n",
    "    input = tf.concat([x_plot_in, t_in], axis=1)\n",
    "    uv = loaded_model(input)\n",
    "    u, v = uv[:, 0], uv[:, 1]\n",
    "    density = u**2 + v**2\n",
    "    # psi_Re, psi_Im = normalization(x_min, x_max, N, u, v)\n",
    "    # density = psi_Re**2 + psi_Im**2\n",
    "    density_interior.append(density)\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "contour = plt.contourf(X_grid, T_grid, density_interior, levels=100, cmap=\"viridis\")\n",
    "plt.colorbar(contour, label=r'$|\\Psi(x,t)|^2$')\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$t$')\n",
    "plt.title(f'Predicted $|\\Psi(x,t)|^2$ with $\\omega={w_choice}$')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "################## Plot: Initial Condition ###############################\n",
    "\n",
    "X = tf.concat([x_is, t_is], axis=1)\n",
    "uv = loaded_model(X)\n",
    "u, v = uv[:, 0:1], uv[:, 1:2]\n",
    "# psi_Re, psi_Im = normalization(x_min, x_max, N_i, u, v)\n",
    "# density_initial = psi_Re**2 + psi_Im**2\n",
    "\n",
    "plt.scatter(x_i, u**2 + v**2, label=r'Predicted $|\\Psi(x,0)|^2$')\n",
    "# plt.scatter(x_i, density_initial, label=r'Normalized Predicted $|\\Psi(x,0)|^2$')\n",
    "plt.scatter(x_i, tf.math.abs(psi_i)**2, label=r'Expected $|\\Psi(x,0)|^2$')\n",
    "plt.xlabel('x')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "################## Plot: Boundary Condition ###############################\n",
    "\n",
    "X = tf.concat([x_bs, t_bs], axis=1)\n",
    "uv = loaded_model(X)\n",
    "u, v = uv[:, 0:1], uv[:, 1:2]\n",
    "# psi_Re, psi_Im = normalization(x_min, x_max, N_b, u, v)\n",
    "# density_boundary = psi_Re**2 + psi_Im**2\n",
    "\n",
    "plt.scatter(t_b, u**2 + v**2, label=r'Predicted $|\\Psi(x_b,t)|^2$')\n",
    "# plt.scatter(t_b, density_boundary, label=r'Normalized Predicted $|\\Psi(x_b,t)|^2$')\n",
    "plt.xlabel('t')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffbf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_list = []\n",
    "\n",
    "# Compute theoretical |Psi(x,t)|^2 as before\n",
    "def U_0(x, t):\n",
    "    w = 1.0\n",
    "    return np.exp(-1j * 0.5 * w * t) * (w/np.pi)**0.25 * np.exp(-w * x**2 / 2.0)\n",
    "\n",
    "def U_1(x, t):\n",
    "    w = 1.0\n",
    "    return np.exp(-1j * 1.5 * w * t) * (w/np.pi)**0.25 * np.exp(-w * x**2 / 2.0) * x * np.sqrt(2.0*w)\n",
    "\n",
    "# Define time steps\n",
    "t_test = [0, np.pi/2.0, np.pi, 1.5*np.pi, 2.0*np.pi]\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, len(t_test), figsize=(15, 5), sharey=True)\n",
    "\n",
    "for i, t_val in enumerate(t_test):\n",
    "    t_in = tf.ones_like(x_is) * t_val\n",
    "    t_ins = scale_inputs(t_in, t_min, t_max)\n",
    "    X = tf.concat([x_is, t_ins], axis=1)\n",
    "    uv = loaded_model(X)\n",
    "    u, v = uv[:, 0:1], uv[:, 1:2]\n",
    "    # psi_Re, psi_Im = normalization(x_min, x_max, N_b, u, v)\n",
    "    density_pred = u**2 + v**2\n",
    "\n",
    "    t_true = tf.ones_like(x_i) * t_val\n",
    "    psi_true = (1.0 / np.sqrt(2.0)) * (U_0(x_i.numpy(), t_true.numpy()) + U_1(x_i.numpy(), t_true.numpy()))\n",
    "    density_true = np.abs(psi_true)**2\n",
    "\n",
    "    # # Compute and store MSE (interpolating prediction to x_true if necessary)\n",
    "    # density_pred_np = density_pred.numpy().squeeze()\n",
    "    # x_i_np = x_i.numpy().squeeze()\n",
    "\n",
    "    # Interpolate model prediction to match x_true\n",
    "    # density_pred_interp = np.interp(x_i, x_i_np, density_pred_np)\n",
    "    mse = mean_squared_error(density_true, density_pred)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "    ax = axs[i]\n",
    "    # ax.scatter(x_i, density, s=10, label=\"Normalized\", alpha=0.7)\n",
    "    ax.scatter(x_i, density_pred, s=10, label=\"Prediction\", alpha=0.5)\n",
    "    ax.scatter(x_i, density_true, s=10, label=\"True\", alpha=0.6)\n",
    "    ax.set_title(f\"$t = {t_val:.2f}$, MSE={mse:.2e}\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(r\"$|\\Psi(x,t)|^2$\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Add a single legend and adjust layout\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right', ncol=2)\n",
    "fig.suptitle(\"Predicted $|\\Psi(x,t)|^2$ at Different Time Steps\", fontsize=14)\n",
    "# plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "plt.show()\n",
    "\n",
    "# Optional: Print summary\n",
    "for t_val, mse in zip(t_test, mse_list):\n",
    "    print(f\"t = {t_val:.2f}, MSE = {mse:.4e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
